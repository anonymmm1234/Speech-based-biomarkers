{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2ceae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "from parselmouth.praat import call\n",
    "import parselmouth\n",
    "import librosa\n",
    "from librosa import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781973ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory of audio files\n",
    "\n",
    "#Pataka_dir = r\"Dataset/healthy_data/test_5_pataka_healthy\"\n",
    "Pataka_dir = r\"Concussion/Final_Dataset_Without_Silence/Concussed_Dataset without Silence/Concussed_PaTaKa\"\n",
    "#Pataka_dir = r\"test_5_pataka_healthy\"\n",
    "\n",
    "Pataka_audio = glob.glob(Pataka_dir + '/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5486b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for measuring pitch\n",
    "\n",
    "def measurePitch(voice, f0min, f0max, unit):\n",
    "\n",
    "    sound = parselmouth.Sound(voice) # read the sound\n",
    "    duration = call(sound, \"Get total duration\") # duration\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max) #create a praat pitch object\n",
    "    meanF0 = call(pitch, \"Get mean\", 0, 0, unit) # get mean pitch\n",
    "    stdevF0 = call(pitch, \"Get standard deviation\", 0 ,0, unit) # get standard deviation\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, f0min, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    return duration, meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c3cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measurePitch(Pataka_audio[0],75,300,'Hertz')\n",
    "import statistics\n",
    "from parselmouth.praat import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb697514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measureFormants(sound,f0min,f0max):\n",
    "    sound = parselmouth.Sound(sound) # read the sound\n",
    "    pitch = call(sound, \"To Pitch (cc)\", 0, f0min, 15, 'no', 0.03, 0.45, 0.01, 0.35, 0.14, f0max)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0025, 5, 5000, 0.025, 50)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "    \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "    \n",
    "    # calculate mean formants across pulses\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    # calculate median formants across pulses, this is what is used in all subsequent calcualtions\n",
    "    # you can use mean if you want, just edit the code in the boxes below to replace median with mean\n",
    "    f1_median = statistics.median(f1_list)\n",
    "    f2_median = statistics.median(f2_list)\n",
    "    f3_median = statistics.median(f3_list)\n",
    "    f4_median = statistics.median(f4_list)\n",
    "    \n",
    "    return f1_mean, f2_mean, f3_mean, f4_mean, f1_median, f2_median, f3_median, f4_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362bc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectral Feature Extraction\n",
    "\n",
    "#stft used short-term Fourier transformation to compute Chroma features. STFT represents information about the classification of pitch and signal structure.\n",
    "featureList1 = [\n",
    "    feature.chroma_stft,\n",
    "    feature.spectral_centroid,\n",
    "    feature.spectral_bandwidth,\n",
    "    feature.spectral_rolloff,\n",
    "    feature.chroma_cqt,\n",
    "    feature.chroma_cens,\n",
    "    feature.melspectrogram,\n",
    "    feature.mfcc,\n",
    "    feature.spectral_contrast,\n",
    "    feature.poly_features,\n",
    "    feature.tonnetz,\n",
    "]\n",
    "\n",
    "featureList2 = [feature.zero_crossing_rate,\n",
    "               feature.rms,\n",
    "               feature.spectral_flatness]\n",
    "\n",
    "def getFeatureVector(y,sr, order):  \n",
    "    FLRes1 = [ np.mean(funct(y,sr)) for funct in featureList1]\n",
    "    FLRes2 = [ np.mean(funct(y)) for funct in featureList2]\n",
    "\n",
    "    featureVector =   FLRes1 + FLRes2\n",
    "    return featureVector\n",
    "\n",
    "\n",
    "def load_file_from_list(audio):\n",
    "    y1, sr1 = librosa.load(audio, sr = None)\n",
    "    return getFeatureVector(y = y1, sr = sr1, order = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a2ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639.6516488026502, 1252.6951487175188, 2318.655704211161, 3237.6729867263202, 664.2192300738512, 1183.0215747349985, 2314.8068766291294, 3256.287619760415)\n",
      "(4.4468125, 84.62635239126497, 3.8911593554606214, 8.426532965728333, 0.01833870613229295, 0.00021649974126701358, 0.007629419722967106, 0.00927034488760135, 0.022888259168901318, 0.10360515346450352, 0.9554832238390762, 0.030847527710242434, 0.05112265028598257, 0.2045214027274718, 0.0925425831307273)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45033005,\n",
       " 1418.8846473355964,\n",
       " 1243.1201393442643,\n",
       " 2515.456384892086,\n",
       " 0.5916079,\n",
       " 0.28298867,\n",
       " 0.2532607,\n",
       " -26.762688,\n",
       " 20.034210841753623,\n",
       " 0.3552900161503918,\n",
       " 0.0029788170347740243,\n",
       " 0.1603564804406475,\n",
       " 0.027023422,\n",
       " 0.019698747]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(measureFormants(Pataka_audio[9],75,300))\n",
    "print(measurePitch(Pataka_audio[9], 75, 300, 'Hertz'))\n",
    "lst = load_file_from_list(Pataka_audio[9])\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5527bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5589247"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features_Pataka\n",
    "lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9224a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(Audio):\n",
    "    file_list = []\n",
    "    duration_list = []\n",
    "    mean_F0_list = []\n",
    "    sd_F0_list = []\n",
    "    hnr_list = []\n",
    "    localJitter_list = []\n",
    "    localabsoluteJitter_list = []\n",
    "    rapJitter_list = []\n",
    "    ppq5Jitter_list = []\n",
    "    ddpJitter_list = []\n",
    "    localShimmer_list = []\n",
    "    localdbShimmer_list = []\n",
    "    apq3Shimmer_list = []\n",
    "    aqpq5Shimmer_list = []\n",
    "    apq11Shimmer_list = []\n",
    "    ddaShimmer_list = []\n",
    "    f1_mean_list = []\n",
    "    f2_mean_list = []\n",
    "    f3_mean_list = []\n",
    "    f4_mean_list = []\n",
    "    f1_median_list = []\n",
    "    f2_median_list = []\n",
    "    f3_median_list = []\n",
    "    f4_median_list = []\n",
    "    #Spectrul_Features\n",
    "    chroma_stft = []\n",
    "    spectral_centroid= []\n",
    "    spectral_bandwidth= []\n",
    "    spectral_rolloff= []\n",
    "    chroma_cqt= []\n",
    "    chroma_cens= []\n",
    "    melspectrogram= []\n",
    "    mfcc= []\n",
    "    spectral_contrast= []\n",
    "    poly_features= []\n",
    "    tonnetz= []\n",
    "    zero_crossing_rate= []\n",
    "    rms= []\n",
    "    spectral_flatness= []\n",
    "    \n",
    "\n",
    "    \n",
    "    cnt=1\n",
    "    for i in Audio:\n",
    "        aud_id = i.split('.')[0].strip()\n",
    "        aud_id = aud_id.split('\\\\')[1]\n",
    "        print(cnt,aud_id)\n",
    "        cnt = cnt+1\n",
    "        \n",
    "        #Pitch Features\n",
    "        (duration, meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, \n",
    "        localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer) = measurePitch(i, 75, 300, 'Hertz')\n",
    "        #sound = parselmouth.Sound(i)\n",
    "        \n",
    "        #Formants Features\n",
    "        (f1_mean, f2_mean, f3_mean, f4_mean, f1_median, f2_median, f3_median, f4_median) = measureFormants(i, 75, 300)\n",
    "        file_list.append(aud_id) # make an ID list\n",
    "        \n",
    "        \n",
    "        #Spectral Features Extraction\n",
    "        spectral_feature_list = load_file_from_list(i)\n",
    "        chroma_stft.append(spectral_feature_list[0])\n",
    "        spectral_centroid.append(spectral_feature_list[1])\n",
    "        spectral_bandwidth.append(spectral_feature_list[2])\n",
    "        spectral_rolloff.append(spectral_feature_list[3])\n",
    "        chroma_cqt.append(spectral_feature_list[4])\n",
    "        chroma_cens.append(spectral_feature_list[5])\n",
    "        melspectrogram.append(spectral_feature_list[6])\n",
    "        mfcc.append(spectral_feature_list[7])\n",
    "        spectral_contrast.append(spectral_feature_list[8])\n",
    "        poly_features.append(spectral_feature_list[9])\n",
    "        tonnetz.append(spectral_feature_list[10])\n",
    "        zero_crossing_rate.append(spectral_feature_list[11])\n",
    "        rms.append(spectral_feature_list[12])\n",
    "        spectral_flatness.append(spectral_feature_list[13])\n",
    "        \n",
    "        \n",
    "        duration_list.append(duration) # make duration list\n",
    "        mean_F0_list.append(meanF0) # make a mean F0 list\n",
    "        sd_F0_list.append(stdevF0) # make a sd F0 list\n",
    "        hnr_list.append(hnr) #add HNR data\n",
    "        \n",
    "        # add raw jitter and shimmer measures\n",
    "        localJitter_list.append(localJitter)\n",
    "        localabsoluteJitter_list.append(localabsoluteJitter)\n",
    "        rapJitter_list.append(rapJitter)\n",
    "        ppq5Jitter_list.append(ppq5Jitter)\n",
    "        ddpJitter_list.append(ddpJitter)\n",
    "        localShimmer_list.append(localShimmer)\n",
    "        localdbShimmer_list.append(localdbShimmer)\n",
    "        apq3Shimmer_list.append(apq3Shimmer)\n",
    "        aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "        apq11Shimmer_list.append(apq11Shimmer)\n",
    "        ddaShimmer_list.append(ddaShimmer)\n",
    "        \n",
    "        # add the formant data\n",
    "        f1_mean_list.append(f1_mean)\n",
    "        f2_mean_list.append(f2_mean)\n",
    "        f3_mean_list.append(f3_mean)\n",
    "        f4_mean_list.append(f4_mean)\n",
    "        f1_median_list.append(f1_median)\n",
    "        f2_median_list.append(f2_median)\n",
    "        f3_median_list.append(f3_median)\n",
    "        f4_median_list.append(f4_median)\n",
    "    \n",
    "    #Load features in data frame\n",
    "                       #pd.DataFrame(np.column_stack([duration_list1,\n",
    "    features_Pataka = pd.DataFrame(np.column_stack([file_list, duration_list, mean_F0_list, sd_F0_list, hnr_list, \n",
    "                                   localJitter_list, localabsoluteJitter_list, rapJitter_list, \n",
    "                                   ppq5Jitter_list, ddpJitter_list, localShimmer_list, \n",
    "                                   localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, \n",
    "                                   apq11Shimmer_list, ddaShimmer_list, f1_mean_list, \n",
    "                                   f2_mean_list, f3_mean_list, f4_mean_list, \n",
    "                                   f1_median_list, f2_median_list, f3_median_list, \n",
    "                                   f4_median_list, chroma_stft, spectral_centroid, spectral_bandwidth, spectral_rolloff,\n",
    "                                   zero_crossing_rate, chroma_cqt, chroma_cens, melspectrogram, mfcc, spectral_contrast, \n",
    "                                   poly_features, tonnetz, rms, spectral_flatness]),\n",
    "                                   columns=['ID_audio','duration', 'meanF0Hz', 'stdevF0Hz', 'HNR', \n",
    "                                            'localJitter', 'localabsoluteJitter', 'rapJitter', \n",
    "                                            'ppq5Jitter', 'ddpJitter', 'localShimmer', \n",
    "                                            'localdbShimmer', 'apq3Shimmer', 'apq5Shimmer', \n",
    "                                            'apq11Shimmer', 'ddaShimmer', 'f1_mean', 'f2_mean', \n",
    "                                            'f3_mean', 'f4_mean', 'f1_median', \n",
    "                                            'f2_median', 'f3_median', 'f4_median','chroma_stft','spectral_centroid',\n",
    "                                            'spectral_bandwidth','spectral_rolloff','zero_crossing_rate','chroma_cqt',\n",
    "                                            'chroma_cens','melspectrogram','mfcc','spectral_contrast',\n",
    "                                            'poly_features','tonnezt','AvgPower','spectral_flatness',])\n",
    "    return features_Pataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5025383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neurodegenarative Pataka test\n",
    "#Pataka_dir = r\"Dataset/Neurodegenerative_Diseases/test5_PaTaKa\"\n",
    "#Pataka_dir = r\"test_5_pataka_healthy\"\n",
    "Pataka_audio = glob.glob(Pataka_dir + '/*.wav')\n",
    "Pataka_for_ALS_PD_Combined = extract_feature(Pataka_audio)\n",
    "Pataka_for_ALS_PD_Combined_without_NAN = Pataka_for_ALS_PD_Combined.dropna()\n",
    "#Pataka_for_ALS_PD_Combined_without_NAN.to_csv('Dataset/healthy_data/test_5_pataka_healthy/features_for_healthy.csv')\n",
    "Pataka_for_ALS_PD_Combined_without_NAN.to_csv('features_for_ND_T5_Pataka.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
