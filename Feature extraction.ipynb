{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2ceae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "from parselmouth.praat import call\n",
    "import parselmouth\n",
    "import librosa\n",
    "from librosa import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781973ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory of audio files\n",
    "\n",
    "#Pataka_dir = r\"Dataset/healthy_data/test_5_pataka_healthy\"\n",
    "Pataka_dir = r\"Concussion/Final_Dataset_Without_Silence/Concussed_Dataset without Silence/Concussed_PaTaKa\"\n",
    "#Pataka_dir = r\"test_5_pataka_healthy\"\n",
    "\n",
    "Pataka_audio = glob.glob(Pataka_dir + '/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5486b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for measuring pitch\n",
    "\n",
    "def measurePitch(voice, f0min, f0max, unit):\n",
    "\n",
    "    sound = parselmouth.Sound(voice) # read the sound\n",
    "    duration = call(sound, \"Get total duration\") # duration\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max) #create a praat pitch object\n",
    "    meanF0 = call(pitch, \"Get mean\", 0, 0, unit) # get mean pitch\n",
    "    stdevF0 = call(pitch, \"Get standard deviation\", 0 ,0, unit) # get standard deviation\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, f0min, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    return duration, meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c3cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measurePitch(Pataka_audio[0],75,300,'Hertz')\n",
    "import statistics\n",
    "from parselmouth.praat import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb697514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measureFormants(sound,f0min,f0max):\n",
    "    sound = parselmouth.Sound(sound) # read the sound\n",
    "    pitch = call(sound, \"To Pitch (cc)\", 0, f0min, 15, 'no', 0.03, 0.45, 0.01, 0.35, 0.14, f0max)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0025, 5, 5000, 0.025, 50)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "    \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "    \n",
    "    # calculate mean formants across pulses\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    # calculate median formants across pulses, this is what is used in all subsequent calcualtions\n",
    "    # you can use mean if you want, just edit the code in the boxes below to replace median with mean\n",
    "    f1_median = statistics.median(f1_list)\n",
    "    f2_median = statistics.median(f2_list)\n",
    "    f3_median = statistics.median(f3_list)\n",
    "    f4_median = statistics.median(f4_list)\n",
    "    \n",
    "    return f1_mean, f2_mean, f3_mean, f4_mean, f1_median, f2_median, f3_median, f4_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362bc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectral Feature Extraction\n",
    "\n",
    "#stft used short-term Fourier transformation to compute Chroma features. STFT represents information about the classification of pitch and signal structure.\n",
    "featureList1 = [\n",
    "    feature.chroma_stft,\n",
    "    feature.spectral_centroid,\n",
    "    feature.spectral_bandwidth,\n",
    "    feature.spectral_rolloff,\n",
    "    feature.chroma_cqt,\n",
    "    feature.chroma_cens,\n",
    "    feature.melspectrogram,\n",
    "    feature.mfcc,\n",
    "    feature.spectral_contrast,\n",
    "    feature.poly_features,\n",
    "    feature.tonnetz,\n",
    "]\n",
    "\n",
    "featureList2 = [feature.zero_crossing_rate,\n",
    "               feature.rms,\n",
    "               feature.spectral_flatness]\n",
    "\n",
    "def getFeatureVector(y,sr, order):  \n",
    "    FLRes1 = [ np.mean(funct(y,sr)) for funct in featureList1]\n",
    "    FLRes2 = [ np.mean(funct(y)) for funct in featureList2]\n",
    "\n",
    "    featureVector =   FLRes1 + FLRes2\n",
    "    return featureVector\n",
    "\n",
    "\n",
    "def load_file_from_list(audio):\n",
    "    y1, sr1 = librosa.load(audio, sr = None)\n",
    "    return getFeatureVector(y = y1, sr = sr1, order = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a2ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639.6516488026502, 1252.6951487175188, 2318.655704211161, 3237.6729867263202, 664.2192300738512, 1183.0215747349985, 2314.8068766291294, 3256.287619760415)\n",
      "(4.4468125, 84.62635239126497, 3.8911593554606214, 8.426532965728333, 0.01833870613229295, 0.00021649974126701358, 0.007629419722967106, 0.00927034488760135, 0.022888259168901318, 0.10360515346450352, 0.9554832238390762, 0.030847527710242434, 0.05112265028598257, 0.2045214027274718, 0.0925425831307273)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45033005,\n",
       " 1418.8846473355964,\n",
       " 1243.1201393442643,\n",
       " 2515.456384892086,\n",
       " 0.5916079,\n",
       " 0.28298867,\n",
       " 0.2532607,\n",
       " -26.762688,\n",
       " 20.034210841753623,\n",
       " 0.3552900161503918,\n",
       " 0.0029788170347740243,\n",
       " 0.1603564804406475,\n",
       " 0.027023422,\n",
       " 0.019698747]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(measureFormants(Pataka_audio[9],75,300))\n",
    "print(measurePitch(Pataka_audio[9], 75, 300, 'Hertz'))\n",
    "lst = load_file_from_list(Pataka_audio[9])\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5527bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5589247"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features_Pataka\n",
    "lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9224a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(Audio):\n",
    "    file_list = []\n",
    "    duration_list = []\n",
    "    mean_F0_list = []\n",
    "    sd_F0_list = []\n",
    "    hnr_list = []\n",
    "    localJitter_list = []\n",
    "    localabsoluteJitter_list = []\n",
    "    rapJitter_list = []\n",
    "    ppq5Jitter_list = []\n",
    "    ddpJitter_list = []\n",
    "    localShimmer_list = []\n",
    "    localdbShimmer_list = []\n",
    "    apq3Shimmer_list = []\n",
    "    aqpq5Shimmer_list = []\n",
    "    apq11Shimmer_list = []\n",
    "    ddaShimmer_list = []\n",
    "    f1_mean_list = []\n",
    "    f2_mean_list = []\n",
    "    f3_mean_list = []\n",
    "    f4_mean_list = []\n",
    "    f1_median_list = []\n",
    "    f2_median_list = []\n",
    "    f3_median_list = []\n",
    "    f4_median_list = []\n",
    "    #Spectrul_Features\n",
    "    chroma_stft = []\n",
    "    spectral_centroid= []\n",
    "    spectral_bandwidth= []\n",
    "    spectral_rolloff= []\n",
    "    chroma_cqt= []\n",
    "    chroma_cens= []\n",
    "    melspectrogram= []\n",
    "    mfcc= []\n",
    "    spectral_contrast= []\n",
    "    poly_features= []\n",
    "    tonnetz= []\n",
    "    zero_crossing_rate= []\n",
    "    rms= []\n",
    "    spectral_flatness= []\n",
    "    \n",
    "\n",
    "    \n",
    "    cnt=1\n",
    "    for i in Audio:\n",
    "        aud_id = i.split('.')[0].strip()\n",
    "        aud_id = aud_id.split('\\\\')[1]\n",
    "        print(cnt,aud_id)\n",
    "        cnt = cnt+1\n",
    "        \n",
    "        #Pitch Features\n",
    "        (duration, meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, \n",
    "        localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer) = measurePitch(i, 75, 300, 'Hertz')\n",
    "        #sound = parselmouth.Sound(i)\n",
    "        \n",
    "        #Formants Features\n",
    "        (f1_mean, f2_mean, f3_mean, f4_mean, f1_median, f2_median, f3_median, f4_median) = measureFormants(i, 75, 300)\n",
    "        file_list.append(aud_id) # make an ID list\n",
    "        \n",
    "        \n",
    "        #Spectral Features Extraction\n",
    "        spectral_feature_list = load_file_from_list(i)\n",
    "        chroma_stft.append(spectral_feature_list[0])\n",
    "        spectral_centroid.append(spectral_feature_list[1])\n",
    "        spectral_bandwidth.append(spectral_feature_list[2])\n",
    "        spectral_rolloff.append(spectral_feature_list[3])\n",
    "        chroma_cqt.append(spectral_feature_list[4])\n",
    "        chroma_cens.append(spectral_feature_list[5])\n",
    "        melspectrogram.append(spectral_feature_list[6])\n",
    "        mfcc.append(spectral_feature_list[7])\n",
    "        spectral_contrast.append(spectral_feature_list[8])\n",
    "        poly_features.append(spectral_feature_list[9])\n",
    "        tonnetz.append(spectral_feature_list[10])\n",
    "        zero_crossing_rate.append(spectral_feature_list[11])\n",
    "        rms.append(spectral_feature_list[12])\n",
    "        spectral_flatness.append(spectral_feature_list[13])\n",
    "        \n",
    "        \n",
    "        duration_list.append(duration) # make duration list\n",
    "        mean_F0_list.append(meanF0) # make a mean F0 list\n",
    "        sd_F0_list.append(stdevF0) # make a sd F0 list\n",
    "        hnr_list.append(hnr) #add HNR data\n",
    "        \n",
    "        # add raw jitter and shimmer measures\n",
    "        localJitter_list.append(localJitter)\n",
    "        localabsoluteJitter_list.append(localabsoluteJitter)\n",
    "        rapJitter_list.append(rapJitter)\n",
    "        ppq5Jitter_list.append(ppq5Jitter)\n",
    "        ddpJitter_list.append(ddpJitter)\n",
    "        localShimmer_list.append(localShimmer)\n",
    "        localdbShimmer_list.append(localdbShimmer)\n",
    "        apq3Shimmer_list.append(apq3Shimmer)\n",
    "        aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "        apq11Shimmer_list.append(apq11Shimmer)\n",
    "        ddaShimmer_list.append(ddaShimmer)\n",
    "        \n",
    "        # add the formant data\n",
    "        f1_mean_list.append(f1_mean)\n",
    "        f2_mean_list.append(f2_mean)\n",
    "        f3_mean_list.append(f3_mean)\n",
    "        f4_mean_list.append(f4_mean)\n",
    "        f1_median_list.append(f1_median)\n",
    "        f2_median_list.append(f2_median)\n",
    "        f3_median_list.append(f3_median)\n",
    "        f4_median_list.append(f4_median)\n",
    "    \n",
    "    #Load features in data frame\n",
    "                       #pd.DataFrame(np.column_stack([duration_list1,\n",
    "    features_Pataka = pd.DataFrame(np.column_stack([file_list, duration_list, mean_F0_list, sd_F0_list, hnr_list, \n",
    "                                   localJitter_list, localabsoluteJitter_list, rapJitter_list, \n",
    "                                   ppq5Jitter_list, ddpJitter_list, localShimmer_list, \n",
    "                                   localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, \n",
    "                                   apq11Shimmer_list, ddaShimmer_list, f1_mean_list, \n",
    "                                   f2_mean_list, f3_mean_list, f4_mean_list, \n",
    "                                   f1_median_list, f2_median_list, f3_median_list, \n",
    "                                   f4_median_list, chroma_stft, spectral_centroid, spectral_bandwidth, spectral_rolloff,\n",
    "                                   zero_crossing_rate, chroma_cqt, chroma_cens, melspectrogram, mfcc, spectral_contrast, \n",
    "                                   poly_features, tonnetz, rms, spectral_flatness]),\n",
    "                                   columns=['ID_audio','duration', 'meanF0Hz', 'stdevF0Hz', 'HNR', \n",
    "                                            'localJitter', 'localabsoluteJitter', 'rapJitter', \n",
    "                                            'ppq5Jitter', 'ddpJitter', 'localShimmer', \n",
    "                                            'localdbShimmer', 'apq3Shimmer', 'apq5Shimmer', \n",
    "                                            'apq11Shimmer', 'ddaShimmer', 'f1_mean', 'f2_mean', \n",
    "                                            'f3_mean', 'f4_mean', 'f1_median', \n",
    "                                            'f2_median', 'f3_median', 'f4_median','chroma_stft','spectral_centroid',\n",
    "                                            'spectral_bandwidth','spectral_rolloff','zero_crossing_rate','chroma_cqt',\n",
    "                                            'chroma_cens','melspectrogram','mfcc','spectral_contrast',\n",
    "                                            'poly_features','tonnezt','AvgPower','spectral_flatness',])\n",
    "    return features_Pataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5025383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 AdamsHSMen_01040bd7bd90397d87d4bb0c97247339_1413488957_Concussionsuspected_test6_MicrophoneWired\n",
      "2 AdamsHSMen_38be5a22d53fe9179d1ef365896fca63_1408063085_Concussionsuspected_test6_MicrophoneWired\n",
      "3 AdamsHSMen_494c90c16bee5ba54360e283f092fa1d_1413489411_Concussionsuspected_test6_MicrophoneWired\n",
      "4 AdamsHSMen_78e13089c3a29915c5b5a6ae7420b1e6_1413322592_Concussionsuspected_test6_MicrophoneWired\n",
      "5 AdamsHSMen_7ba7c38cf9bde4f9ee15bc2f312741fd_1408061069_Concussionsuspected_test6_MicrophoneWired\n",
      "6 AdamsHSMen_ad8aabab2dfdd090fc4c7f2a055cc472_1413324295_Concussionsuspected_test6_MicrophoneWired\n",
      "7 AdamsHSMen_d48b9aaf6ebd035721a98bcd96d28ecf_1410468585_Concussionsuspected_test6_MicrophoneWired\n",
      "8 AdrianCollegeMen_bf604a6c01408f6c6d0ad26405883977_1413918186_Concussionsuspected_test6_MicrophoneBuiltIn\n",
      "9 AdrianCollegeWomen_55036df36811f349410313d860d25bb1_1414184762_Concussionsuspected_test6_MicrophoneWired\n",
      "10 AlbionCollegeMen_1036383f9e9458e0080f716963fdc5ad_1412446765_Concussionsuspected_test6_MicrophoneWired\n",
      "11 AlbionCollegeMen_bc1d181f3c2201a698b2de389f3335f1_1408633342_Concussionsuspected_test6_MicrophoneWired\n",
      "12 AlbionCollegeMen_c836efffd0859e7e6a358c6c19e18862_1409105158_Concussionsuspected_test6_MicrophoneWired\n",
      "13 AlbionCollegeMen_d88485aa6a0b38ad9245ef1aa1456a9a_1408628921_Concussionsuspected_test6_MicrophoneWired\n",
      "14 AlbionCollegeMen_da9e713c687201ecb9c54999008610bb_1411504082_Concussionsuspected_test6_MicrophoneWired\n",
      "15 AlbionCollegeMen_fa3a0068862a40e78eb0aa1f8981e86b_1414537471_Concussionsuspected_test6_MicrophoneWired\n",
      "16 ArchbishopJohnCarrollHSMen_2e4e81e96a2814993a14091db91ddd1f_1410637685_Concussionsuspected_test6_MicrophoneWired\n",
      "17 ArchbishopWoodHSWomen_385161ec91b0ddde4aa8f8d4466fc3af_1411419274_Concussionsuspected_test6_MicrophoneWired\n",
      "18 ArchbishopWoodHSWomen_a11427189985f8a9b5f9db54ca36fd09_1411418359_Concussionsuspected_test6_MicrophoneWired\n",
      "19 BenetAcademyMen_f05a816c27b8e8515166efe6e698dcf4_1412892318_Concussionsuspected_test6_MicrophoneWired\n",
      "20 BishopDwengerHSMen_5cc1839592db05af153c1ad571d51389_1413234630_Concussionsuspected_test6_MicrophoneWired\n",
      "21 BishopDwengerHSMen_eb172380be2798ca602c6bd122e907ad_1410306187_Concussionsuspected_test6_MicrophoneWired\n",
      "22 CarrollHSMen_2f46189c4794cbe83346dca4cd6d0158_1408043625_Concussionsuspected_test6_MicrophoneWired\n",
      "23 CarrollHSMen_3a7e3d2653ec5105f2e48e72cee64199_1408044928_Concussionsuspected_test6_MicrophoneWired\n",
      "24 CarrollHSMen_5065eb154853e4081d9733b33373eee9_1407450583_Concussionsuspected_test6_MicrophoneWired\n",
      "25 CarrollHSMen_ac665bc250da4e2f2c8d83abdb2596a8_1412031940_Concussionsuspected_test6_MicrophoneWired\n",
      "26 CarrollHSMen_d54f09fe76c510e3c82370b27db4940b_1411153751_Concussionsuspected_test6_MicrophoneWired\n",
      "27 ConcordCommunityHSMen_61975412f6e0ff7e4b579268f12afd83_1407956346_Concussionsuspected_test6_MicrophoneWired\n",
      "28 ConcordiaLutheranMen_0a42faa92673ab153ae8b8518a8c67bf_1411175883_Concussionsuspected_test6_MicrophoneWired\n",
      "29 ConcordiaLutheranMen_82010faf05f6e3c606526409d60bb250_1411177212_Concussionsuspected_test6_MicrophoneWired\n",
      "30 ConcordiaLutheranMen_92a872608bc670a45c4996516dc847e2_1411175606_Concussionsuspected_test6_MicrophoneWired\n",
      "31 CulverAcademyMen_433406aba3322a2819a97d4f45779b6e_1408045031_Concussionsuspected_test6_MicrophoneWired\n",
      "32 FatherJudgeHSMen_a1bb744e64b1c44ebe17cb808684d5e7_1413313105_Concussionsuspected_test6_MicrophoneWired\n",
      "33 FatherJudgeHSMen_caf45fe4866c505f6b0973e3e84f329d_1410644234_Concussionsuspected_test6_MicrophoneWired\n",
      "34 FatherJudgeHSMen_d14c410a2c87310a7fde98541e1e0157_1411153832_Concussionsuspected_test6_MicrophoneWired\n",
      "35 FatherJudgeHSMen_f16151efd51d5a808e31d2baf275e7c2_1410561123_Concussionsuspected_test6_MicrophoneWired\n",
      "36 FatherJudgeHSMen_faf47c322833ca262c5c455008485191_1413311486_Concussionsuspected_test6_MicrophoneWired\n",
      "37 GoshenHSMen_6327233422782263f8c9438c2234ef1f_1412694173_Concussionsuspected_test6_MicrophoneWired\n",
      "38 GoshenHSWomen_d6ad1754b3dd3c4f066786f7216b4301_1412695071_Concussionsuspected_test6_MicrophoneWired\n",
      "39 HuntingtonNorthHSMen_065d1ad2e43790630df77e2b64912b31_1409339640_Concussionsuspected_test6_MicrophoneWired\n",
      "40 HuntingtonNorthHSWomen_8d80193f8336f5f76fc54eefebb9ae53_1411761432_Concussionsuspected_test6_MicrophoneWired\n",
      "41 HuntingtonNorthHSWomen_df0652403c967c3d936171c593f9bce7_1411761623_Concussionsuspected_test6_MicrophoneWired\n",
      "42 LakeForestMen_07c4167c8827964a58c4fa9a1cffa966_1408549867_Concussionsuspected_test6_MicrophoneWired\n",
      "43 LakeForestMen_0eb8bf99ec427828f808c706ef1008a9_1408913499_Concussionsuspected_test6_MicrophoneWired\n",
      "44 LakeForestMen_2d9d2547eb3e2d02179017d5c44b1206_1416763946_Concussionsuspected_test6_MicrophoneWired\n",
      "45 LakeForestMen_3157121c22e8ef7161b0ca91d85f405a_1408631666_Concussionsuspected_test6_MicrophoneWired\n",
      "46 LakeForestMen_3157121c22e8ef7161b0ca91d85f405a_1413907446_Concussionsuspected_test6_MicrophoneWired\n",
      "47 LakeForestMen_3e4c16fa9a6565a5eb8945fb894d5d9c_1408912436_Concussionsuspected_test6_MicrophoneWired\n",
      "48 LakeForestMen_45b7cf7a00598cef4eb432382bfbc7c7_1411842223_Concussionsuspected_test6_MicrophoneWired\n",
      "49 LakeForestMen_4cf96b0aedcc47fb91fb8c22f5267a45_1408550148_Concussionsuspected_test6_MicrophoneWired\n",
      "50 LakeForestMen_67e85ea6debcd554ecf662a1597fff03_1415829639_Concussionsuspected_test6_MicrophoneWired\n",
      "51 LakeForestMen_7547c19fd6de6ff3d468e342af4d94f3_1408663520_Concussionsuspected_test6_MicrophoneWired\n",
      "52 LakeForestMen_7995cf1f1cb428bcd501b977a2e4b29d_1408912675_Concussionsuspected_test6_MicrophoneWired\n",
      "53 LakeForestMen_9ab77f45109792665efd4e2e4c00af48_1409147910_Concussionsuspected_test6_MicrophoneWired\n",
      "54 LakeForestMen_d63ace113efaf78d0e4c90be89115fdb_1415932210_Concussionsuspected_test6_MicrophoneWired\n",
      "55 LakeForestMen_d8d8e73a4a319d2a0c4223d41b0b8786_1408544394_Concussionsuspected_test6_MicrophoneWired\n",
      "56 LakeForestMen_d8d8e73a4a319d2a0c4223d41b0b8786_1416081859_Concussionsuspected_test6_MicrophoneWired\n",
      "57 LakeForestMen_f452a195c77c1501669150c98f0da106_1409010978_Concussionsuspected_test6_MicrophoneWired\n",
      "58 LakeForestMen_f502ff391d8200994cdb57a666dfa61a_1409267531_Concussionsuspected_test6_MicrophoneWired\n",
      "59 LakeForestMen_f5702a784f16ef705c4d1a580de51b50_1408913202_Concussionsuspected_test6_MicrophoneWired\n",
      "60 LakeForestMen_fc2a60a7f18d4368141872110a430f55_1413400966_Concussionsuspected_test6_MicrophoneWired\n",
      "61 LakeForestMen_ff6922a59dc28fd72ff1d0ca49a936ee_1408818153_Concussionsuspected_test6_MicrophoneWired\n",
      "62 LakeForestWomen_2965044dfc3009d5f17a90df7b5a9db6_1408738880_Concussionsuspected_test6_MicrophoneWired\n",
      "63 LakeForestWomen_5231aeedc807559360a84924569c9c32_1408891494_Concussionsuspected_test6_MicrophoneWired\n",
      "64 MishawakaMen_091d893fd99bdbaf0e3ff2df26d959a6_1409359960_Concussionsuspected_test6_MicrophoneWired\n",
      "65 MishawakaMen_310445b20d63b8b7dd50bd06d05af8d3_1406386242_Concussionsuspected_test6_MicrophoneWired\n",
      "66 MishawakaMen_3f0e8c05bc02688e006ebfe077837b5c_1407790797_Concussionsuspected_test6_MicrophoneWired\n",
      "67 MishawakaMen_6d656c4945a1eb704eed381b04cabfdf_1406299211_Concussionsuspected_test6_MicrophoneWired\n",
      "68 MishawakaMen_8ad307828592fbd8d344958d325a3ed8_1410378885_Concussionsuspected_test6_MicrophoneWired\n",
      "69 MishawakaMen_984bc98bd364a53486b263ca45d6fcf0_1409359691_Concussionsuspected_test6_MicrophoneWired\n",
      "70 NorthCentralCollegeMen_12696de90a18993e95d479d7a7270163_1411265960_Concussionsuspected_test6_MicrophoneWired\n",
      "71 NorthCentralCollegeMen_1cfdf1d42b1e29a7ab40a2927cfb7c3c_1411079576_Concussionsuspected_test6_MicrophoneWired\n",
      "72 NorthCentralCollegeMen_1cfdf1d42b1e29a7ab40a2927cfb7c3c_1412611423_Concussionsuspected_test6_MicrophoneWired\n",
      "73 NorthCentralCollegeMen_8b7df8861b12e6028b05d5612799d142_1412094443_Concussionsuspected_test6_MicrophoneWired\n",
      "74 NorthCentralCollegeMen_90a73f8df2a77f7f3146c179fb36415f_1413304104_Concussionsuspected_test6_MicrophoneWired\n",
      "75 NorthCentralCollegeMen_94e19d6c437ccba2332eabf983e5dae7_1412798660_Concussionsuspected_test6_MicrophoneWired\n",
      "76 NorthCentralCollegeMen_da5672fafa9df133fb3e5ac19e81c903_1414712944_Concussionsuspected_test6_MicrophoneWired\n",
      "77 NorthCentralCollegeMen_ebc78ccc769a083e0921b554c66e4e12_1412207147_Concussionsuspected_test6_MicrophoneWired\n",
      "78 NorthwesternHSMen_1d0dd3731fb4fbfe2e0602739ef5b73a_1409344386_Concussionsuspected_test6_MicrophoneWired\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 NorthwesternHSMen_39e8b68c1809b69dc5d1bbd32e444398_1411671161_Concussionsuspected_test6_MicrophoneWired\n",
      "80 NorthwesternHSMen_6ea99df42ec22f7eb3d849dab249247c_1409001336_Concussionsuspected_test6_MicrophoneWired\n",
      "81 OlivetCollegeMen_1b04ecb9021975e9f02597b80176d5b1_1410634068_Concussionsuspected_test6_MicrophoneWired\n",
      "82 OlivetCollegeMen_25b2090e6485d5395ffe8f796c5d0cee_1410901227_Concussionsuspected_test6_MicrophoneWired\n",
      "83 OlivetCollegeMen_4982cfbe96a7d4f373f2563258fda31c_1408632560_Concussionsuspected_test6_MicrophoneWired\n",
      "84 OlivetCollegeMen_840afb48fc75bcde9937ebffd4688781_1408495728_Concussionsuspected_test6_MicrophoneWired\n",
      "85 OlivetCollegeMen_b01ac260781acc4840bc320c36065b8b_1408802407_Concussionsuspected_test6_MicrophoneWired\n",
      "86 OlivetCollegeMen_b6638030bfb6421631d4152a9cc98e8b_1408552010_Concussionsuspected_test6_MicrophoneWired\n",
      "87 RobertMorrisUniversityMen_607e71b23e9b5af04358a315bafbbd8f_1409698322_Concussionsuspected_test6_MicrophoneWired\n",
      "88 RobertMorrisUniversityMen_e981ac89cc5912277f02c2d39db2af40_1408746335_Concussionsuspected_test6_MicrophoneWired\n",
      "89 SaintMarysCollegeWomen_729322c59fc35140652c98872de37bad_1421722756_Concussionsuspected_test6_MicrophoneWired\n",
      "90 SaintMarysCollegeWomen_7c67c7bb3928e685643124cc33195c6c_1411421152_Concussionsuspected_test6_MicrophoneWired\n",
      "91 St\n",
      "92 UniversityOfChicagoMen_65475a859d615c8a6f09be21ad6f998c_1409101190_Concussionsuspected_test6_MicrophoneWired\n",
      "93 UniversityOfChicagoMen_8d60849c93c0ca228352423cae944bc1_1412619055_Concussionsuspected_test6_MicrophoneWired\n",
      "94 UniversityOfChicagoMen_b8cbbdcf26b46ababb12588014a47bb7_1414513049_Concussionsuspected_test6_MicrophoneBuiltIn\n",
      "95 UniversityOfChicagoWomen_2aff369a572c16b157561eb1c5da9d02_1413209279_Concussionsuspected_test6_MicrophoneWired\n"
     ]
    }
   ],
   "source": [
    "#Neurodegenarative Pataka test\n",
    "#Pataka_dir = r\"Dataset/Neurodegenerative_Diseases/test5_PaTaKa\"\n",
    "#Pataka_dir = r\"test_5_pataka_healthy\"\n",
    "Pataka_audio = glob.glob(Pataka_dir + '/*.wav')\n",
    "Pataka_for_ALS_PD_Combined = extract_feature(Pataka_audio)\n",
    "Pataka_for_ALS_PD_Combined_without_NAN = Pataka_for_ALS_PD_Combined.dropna()\n",
    "#Pataka_for_ALS_PD_Combined_without_NAN.to_csv('Dataset/healthy_data/test_5_pataka_healthy/features_for_healthy.csv')\n",
    "Pataka_for_ALS_PD_Combined_without_NAN.to_csv('features_for_ND_T5_Pataka.csv')"
   ]
  },
